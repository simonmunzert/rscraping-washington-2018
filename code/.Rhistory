inaugural_dfm <- dfm(data_corpus_inaugural, remove = c(stopwords("english")), stem = TRUE)
inaugural_dfm # sparsity: proportion of cells that have zero counts
# look at top features
topfeatures(inaugural_dfm)
# make word cloud
textplot_wordcloud(inaugural_dfm, min_count = 25, random_order = FALSE)
warnings()
?textplot_wordcloud
# make word cloud
textplot_wordcloud(inaugural_dfm, max.words = 50, random_order = FALSE)
# make word cloud
textplot_wordcloud(inaugural_dfm, max.words = 100, random_order = FALSE)
# create document-feature matrix, removing stop words
inaugural_dfm <- dfm(data_corpus_inaugural, remove = c(stopwords("english")), remove_punct = TRUE, stem = TRUE)
inaugural_dfm # sparsity: proportion of cells that have zero counts
# look at top features
topfeatures(inaugural_dfm)
# make word cloud
textplot_wordcloud(inaugural_dfm, max.words = 100, random_order = FALSE)
data_corpus_inaugural[1:2]
warnings()
# 1. from a character vector object
inaugural_george_washington <- data_corpus_inaugural[1:2]
class(inaugural_george_washington)
my_tiny_corpus <- corpus(inaugural_george_washington, metacorpus = list(notes = "From G.W."))
summary(my_tiny_corpus)
# 2. from a VCorpus object from the tm package
data(crude, package = "tm")
library("tm")
install.packages("tm")
library(tm)
# 2. from a VCorpus object from the tm package
data(crude, package = "tm")
crude
my_tm_corpus <- corpus(crude)
summary(my_tm_corpus, 5)
?crude
# 3. from a readtext object
txt_files <- list.files("data/inaugural", pattern = "txt$", full.names = TRUE)
txt_files
# 3. from a readtext object
txt_files <- list.files("../data/inaugural", pattern = "txt$", full.names = TRUE)
txt_files
foo <- readtext(txt_files)
foo
inaugural_txts <- readtext(txt_files)
my_txt_corpus <- corpus(inaugural_txts)
summary(my_txt_corpus, 5)
# 4. from a structured file (here: csv)
sz_df <- read_csv("../data/sueddeutsche-articles.csv")
sz_corpus <- readtext("../data/sueddeutsche-articles.csv", text_field = "text") %>% corpus
my_sz_corpus <- readtext("../data/sueddeutsche-articles.csv", text_field = "text") %>% corpus
summary(my_sz_corpus, 5)
# check out readtext() help for more functionality
?readtext
# new corpus
txt_files <- list.files("../data/sotu", pattern = "txt$", full.names = TRUE)
sotu_corpus <- readtext(txt_files) %>% corpus()
summary(sotu_corpus, 5)
# add metadata
sotu_docvars <- read.csv("../data/sotu-metadata.csv", stringsAsFactors = FALSE)
head(sotu_docvars)
docvars(sotu_corpus) <- sotu_docvars
summary(sotu_corpus, 5)
?docvars
sotu_corpus$documents
summary(sotu_corpus)
summary(sotu_corpus, 5)
# subset corpus
sotu_corpus$documents$year <- str_extract(sotu_corpus$documents$Date, "[:digit:]{4}")
summary(sotu_corpus, 5)
# subset corpus
sotu_corpus$documents$year <- str_extract(sotu_corpus$documents$Date, "[:digit:]{4}") %>% as.numeric
sotu_corpus_sub <- corpus_subset(sotu_corpus, year >= 2000)
summary(sotu_corpus_sub)
sotu_corpus_sub <- corpus_subset(sotu_corpus, year >= 2008)
summary(sotu_corpus_sub)
# change units of texts (documents, paragraphs, sentences)
ndoc(sotu_corpus)
source("packages.r")
# new corpus
txt_files <- list.files("../data/sotu", pattern = "txt$", full.names = TRUE)
sotu_corpus <- readtext(txt_files) %>% corpus()
summary(sotu_corpus, 5)
# add metadata
sotu_docvars <- read.csv("../data/sotu-metadata.csv", stringsAsFactors = FALSE)
head(sotu_docvars)
docvars(sotu_corpus) <- sotu_docvars
summary(sotu_corpus, 5)
# subset corpus
sotu_corpus$documents$year <- str_extract(sotu_corpus$documents$Date, "[:digit:]{4}") %>% as.numeric
sotu_corpus_sub <- corpus_subset(sotu_corpus, year >= 2008)
summary(sotu_corpus_sub)
# change units of texts (documents, paragraphs, sentences)
ndoc(sotu_corpus)
sotu_corpus_sent <- corpus_reshape(sotu_corpus, 'sentences')
ndoc(sotu_corpus_sent)
sotu_corpus_sent[1]
# extract tags from text
speach_corp <- corpus("Mr. Smith: Text.
Mrs. Jones: More text.
Mr. Smith: I'm speaking, again.")
speaker_corp <- corpus_segment(speach_corp, pattern = "\\b[A-Z].+\\s[A-Z][a-z]+:", valuetype = "regex")
speaker_corp
?corpus_segment
cbind(texts(speaker_corp), docvars(speaker_corp))
texts(speaker_corp)
texts(sotu_corpus_sub)
foo <- texts(speaker_corp)
class(foo)
?texts
source("packages.r")
load("data/guardianSample.RData")
load("../data/guardianSample.RData")
names(guardianSample)
guardian_corp <- corpus(guardianSample$documents, text_field = "texts")
guardian_toks <- tokens(guardian_corp, remove_punct = TRUE)
guardian_toks[1]
# select tokens starting with capital letters
cap_col <- tokens_select(guardian_toks, '^[A-Z]', valuetype = 'regex', case_insensitive = FALSE, padding = TRUE)
cap_col[1]
# identify and score multi-word expressions (with at least 10 observations)
cap_col <- textstat_collocations(cap_col, min_count = 10)
head(cap_col, 20)
# data available in quanteda!
lengths(data_dictionary_LSD2015)
as.list(data_dictionary_LSD2015[1])$negative[1:50]
as.list(data_dictionary_LSD2015[3])$neg_positive[1:50]
# subset corpus
docvars(guardian_corp, 'year') <- year(docvars(guardian_corp, 'date'))
guardian_corp <- corpus(guardianSample$documents, text_field = "texts")
# subset corpus
docvars(guardian_corp, 'year') <- year(docvars(guardian_corp, 'date'))
docvars(guardian_corp, 'month') <- month(docvars(guardian_corp, 'date'))
docvars(guardian_corp, 'week') <- week(docvars(guardian_corp, 'date'))
guardian_corp <- corpus_subset(guardian_corp, year >= 2016)
guardian_toks <- tokens(guardian_corp, remove_punct = TRUE)
# check sentiment
lsd_toks <- tokens_lookup(guardian_toks, data_dictionary_LSD2015[1:2])
head(lsd_toks, 2)
# DFM from classified tokens
lsd_dfm <- dfm(lsd_toks)
head(lsd_dfm, 5)
# more targeted dictionary analysis
eu <- c('EU', 'europ*', 'european union')
eu_toks <- tokens_keep(guardian_toks, phrase(eu), window = 10)
eu_toks[2]
# grouped DFM
eu_lsd_dfm <- dfm(eu_toks, dictionary = data_dictionary_LSD2015[1:2]) %>%
dfm_group(group = 'week', fill = TRUE)
# plot absolute frequencies
matplot(eu_lsd_dfm, type = 'l', xaxt = 'n', lty = 1, ylab = 'Frequency')
grid()
axis(1, seq_len(ndoc(eu_lsd_dfm)), ymd("2016-01-01") + weeks(seq_len(ndoc(eu_lsd_dfm)) - 1))
legend('topright', col = 1:2, legend = c('Negative', 'Positive'), lty = 1, bg = 'white')
# plot average sentiment
eu_n <- ntoken(dfm(eu_toks, group = docvars(eu_toks, 'week')))
uk <- read.csv("../data/FB-UK-parties.csv", stringsAsFactors = FALSE)
table(uk$party)
table(uk$name)
head(uk)
populist_dict <- dictionary(list(
populism = c(
"elit*",
"consensus*",
"undemocratic*",
"referend*",
"corrupt*",
"propagand*",
"politici*",
"*deceit*",
"*deceiv*",
"*betray*",
"shame*",
"scandal*",
"truth*",
"dishonest*",
"establishm*",
"ruling*")))
# create corpus
fbcorpus <- corpus(uk)
fbdfm <- dfm(fbcorpus, groups = "party")
# normalize for document length: turn word counts into proportions
fbdfm <- dfm_weight(fbdfm, scheme="prop")
# find % of words in populism dictionary
pop <- dfm_lookup(fbdfm, dictionary = populist_dict)
pop * 100
# check precision
kwic(fbcorpus, pattern = 'undemocratic') # sounds good
kwic(fbcorpus, pattern = 'ruling*') # probably not
# check recall
kwic(fbcorpus, pattern = 'unaccountable')
kwic(fbcorpus, pattern = 'dodging')
fbdfm <- dfm(fbcorpus, groups = c("type", "party"))
# turn word counts into proportions
fbdfm <- dfm_weight(fbdfm, scheme="prop")
# find % of words in populism dictionary
pop <- dfm_lookup(fbdfm, dictionary = populist_dict)
pop * 100
liwc <- read.csv("../data/liwc-dictionary.csv", stringsAsFactors = FALSE)
anger.words <- liwc$word[liwc$class=="anger"]
sample(anger.words, 10)
anger <- dfm_lookup(fbdfm, dictionary = dictionary(list('anger'=anger.words)))
anger*100
# create corpus
fbcorpus <- corpus(uk)
fbdfm <- dfm(fbcorpus, groups = "party")
# normalize for document length: turn word counts into proportions
fbdfm <- dfm_weight(fbdfm, scheme="prop")
anger <- dfm_lookup(fbdfm, dictionary = dictionary(list('anger'=anger.words)))
anger*100
class(liwc)
liwc$word[liwc$class == "anger"]
anger_words <- liwc$word[liwc$class == "anger"]
sample(anger_words, 10)
anger <- dfm_lookup(fbdfm, dictionary = dictionary(list('anger' = anger_words)))
anger*100
tweets <- read.csv("../data/UK-tweets.csv", stringsAsFactors=F)
tweets$engaging <- ifelse(tweets$communication=="engaging", 1, 0)
tweets <- tweets[!is.na(tweets$engaging),]
head(tweets)
# substitute handles with @ to avoid overfitting
tweets$text <- gsub('@[0-9_A-Za-z]+', '@', tweets$text)
# substitute handles with @ to avoid overfitting
tweets$text <- gsub('@[0-9_A-Za-z]+', '@', tweets$text)
# further preprocessing
twcorpus <- corpus(tweets$text)
summary(twcorpus)
# keep only tokens that appear in 2 or more tweets
# keep punctuation -- it turns out it can be quite informative.
twdfm <- dfm(twcorpus, remove=stopwords("english"), remove_url=TRUE,
ngrams=1:2, verbose=TRUE) #
twdfm <- dfm_trim(twdfm, min_docfreq = 2, verbose=TRUE)
?remove_twitter
?removePunctuation
?remove_punct
?tokens
# split into training and test set
set.seed(123)
training <- sample(1:nrow(tweets), floor(.80 * nrow(tweets)))
test <- (1:nrow(tweets))[1:nrow(tweets) %in% training == FALSE]
# ridge regression
library(glmnet)
require(doMC)
install.packages("glmnet")
source("packages.r")
# ridge regression
registerDoMC(cores=3) # parallel computing on multiple cores using the doMC package
?registerDoMC
options("cores")
detectCores()
# ridge regression
parallel::detectCores()
?cv.glmnet
twdfm[training,]
tweets$engaging[training]
ridge <- cv.glmnet(twdfm[training,], # x matrix
tweets$engaging[training],  # y response
family = "binomial", # family
alpha = 0,
nfolds = 5, # k-folds cross-validation
parallel = TRUE, # enable parallel computing
intercept = TRUE, #
type.measure = "class")
plot(ridge)
## function to compute accuracy
accuracy <- function(ypred, y){
tab <- table(ypred, y)
return(sum(diag(tab))/sum(tab))
}
# function to compute precision
precision <- function(ypred, y){
tab <- table(ypred, y)
return((tab[2,2])/(tab[2,1]+tab[2,2]))
}
# function to compute recall
recall <- function(ypred, y){
tab <- table(ypred, y)
return(tab[2,2]/(tab[1,2]+tab[2,2]))
}
# computing predicted values
preds <- predict(ridge, twdfm[test,], type="class")
table(preds, tweets$engaging[test]) # confusion matrix
# performance metrics
accuracy(preds, tweets$engaging[test])
precision(preds==1, tweets$engaging[test]==1)
recall(preds==1, tweets$engaging[test]==1)
precision(preds==0, tweets$engaging[test]==0)
recall(preds==0, tweets$engaging[test]==0)
# from the different values of lambda, let's pick the highest one that is
# within one standard error of the best one (why? see "one-standard-error"
# rule -- maximizes parsimony)
best.lambda <- which(ridge$lambda==ridge$lambda.1se)
beta <- ridge$glmnet.fit$beta[,best.lambda]
head(beta)
ridge$lambda
ridge$lambda.1se
summary(ridge)
which(ridge$lambda==ridge$lambda.1se)
# from the different values of lambda, let's pick the highest one that is within one standard error of the best one
best.lambda <- which(ridge$lambda==ridge$lambda.1se)
beta <- ridge$glmnet.fit$beta[,best.lambda]
beta
head(beta)
## identifying predictive features
df <- data.frame(coef = as.numeric(beta),
word = names(beta), stringsAsFactors=F)
df <- df[order(df$coef),]
head(df[,c("coef", "word")], n=30)
paste(df$word[1:30], collapse=", ")
df <- df[order(df$coef, decreasing=TRUE),]
head(df[,c("coef", "word")], n=30)
paste(df$word[1:30], collapse=", ")
# computing predicted values
preds <- predict(lasso, twdfm[test,], type="class")
# lasso regression
lasso <- cv.glmnet(twdfm[training,],
tweets$engaging[training],
family = "binomial",
alpha = 1, # <- here's the difference
nfolds = 5,
parallel = TRUE,
intercept = TRUE,
type.measure = "class")
# computing predicted values
preds <- predict(lasso, twdfm[test,], type="class")
# confusion matrix
table(preds, tweets$engaging[test])
# performance metrics (slightly better!)
accuracy(preds, tweets$engaging[test])
precision(preds==1, tweets$engaging[test]==1)
recall(preds==1, tweets$engaging[test]==1)
precision(preds==0, tweets$engaging[test]==0)
recall(preds==0, tweets$engaging[test]==0)
best.lambda <- which(lasso$lambda==lasso$lambda.1se)
beta <- lasso$glmnet.fit$beta[,best.lambda]
head(beta)
## identifying predictive features
df <- data.frame(coef = as.numeric(beta),
word = names(beta), stringsAsFactors = F)
df <- df[order(df$coef),]
head(df[,c("coef", "word")], n = 30)
paste(df$word[1:30], collapse = ", ")
df <- df[order(df$coef, decreasing = TRUE),]
head(df[,c("coef", "word")], n = 30)
paste(df$word[1:30], collapse = ", ")
# elastic net
enet <- cv.glmnet(twdfm[training,],
tweets$engaging[training],
family = "binomial",
alpha = 0.5, # <- here's the difference
nfolds = 5,
parallel = TRUE,
intercept = TRUE,
type.measure = "class")
# note: this will not cross-validate across values of alpha
# computing predicted values
preds <- predict(enet, twdfm[test,], type="class")
# confusion matrix
table(preds, tweets$engaging[test])
# performance metrics (slightly better!)
accuracy(preds, tweets$engaging[test])
precision(preds==1, tweets$engaging[test]==1)
recall(preds==1, tweets$engaging[test]==1)
precision(preds==0, tweets$engaging[test]==0)
recall(preds==0, tweets$engaging[test]==0)
source("packages.r")
# converting matrix object
X <- as(twdfm, "dgCMatrix")
# parameters to explore
tryEta <- c(1,2)
tryDepths <- c(1,2,4)
# placeholders for now
bestEta = NA
bestDepth = NA
bestAcc = 0
for(eta in tryEta){
for(dp in tryDepths){
bst <- xgb.cv(data = X[training,],
label =  tweets$engaging[training],
max.depth = dp,
eta = eta,
nthread = 4,
nround = 500,
nfold=5,
print_every_n = 100L,
objective = "binary:logistic")
# cross-validated accuracy
acc <- 1-mean(tail(bst$evaluation_log$test_error_mean))
cat("Results for eta=",eta," and depth=", dp, " : ",
acc," accuracy.\n",sep="")
if(acc>bestAcc){
bestEta=eta
bestAcc=acc
bestDepth=dp
}
}
}
cat("Best model has eta=",bestEta," and depth=", bestDepth, " : ",
bestAcc," accuracy.\n",sep="")
# running best model
rf <- xgboost(data = X[training,],
label = tweets$engaging[training],
max.depth = bestDepth,
eta = bestEta,
nthread = 4,
nround = 1000,
print_every_n=100L,
objective = "binary:logistic")
# out-of-sample accuracy
preds <- predict(rf, X[test,])
cat("\nAccuracy on test set=", round(accuracy(preds>.50, tweets$engaging[test]),3))
cat("\nPrecision(1) on test set=", round(precision(preds>.50, tweets$engaging[test]),3))
cat("\nRecall(1) on test set=", round(recall(preds>.50, tweets$engaging[test]),3))
cat("\nPrecision(0) on test set=", round(precision(preds<.50, tweets$engaging[test]==0),3))
cat("\nRecall(0) on test set=", round(recall(preds<.50, tweets$engaging[test]==0),3))
# feature importance
labels <- dimnames(X)[[2]]
importance <- xgb.importance(labels, model = rf, data=X, label=tweets$engaging)
importance <- importance[order(importance$Gain, decreasing=TRUE),]
head(importance, n=20)
# adding sign
sums <- list()
for (v in 0:1){
sums[[v+1]] <- colSums(X[tweets[,"engaging"]==v,])
}
sums <- do.call(cbind, sums)
sign <- apply(sums, 1, which.max)
df <- data.frame(
Feature = labels,
sign = sign-1,
stringsAsFactors=F)
importance <- merge(importance, df, by="Feature")
## best predictors
for (v in 0:1){
cat("\n\n")
cat("value==", v)
importance <- importance[order(importance$Gain, decreasing=TRUE),]
print(head(importance[importance$sign==v,], n=50))
cat("\n")
cat(paste(unique(head(importance$Feature[importance$sign==v], n=50)), collapse=", "))
}
source("packages.r")
source("packages.r")
# parse with read_html
parsed_doc <- read_html("https://google.com")
parsed_doc
# parse with read_html
parsed_doc <- read_html("https://google.com")
parsed_doc
# parse with read_html
parsed_doc <- read_html("https://google.de")
parsed_doc
parsed_doc <- read_html("https://facebook.com")
parsed_doc
# parse with read_html
parsed_doc <- read_html("https://www.google.com")
parsed_doc
class(parsed_doc)
parsed_doc <- read_html("https://www.facebook.com")
parsed_doc <- read_html("https://www.facebook.com")
parsed_doc <- read_html("https://www.facebook.com")
parsed_doc
# parse with read_html
parsed_doc <- read_html("https://www.google.com")
parsed_doc
Sys.getlocale()
Sys.setlocale("LC_CTYPE", "en_US.UTF-8")
parsed_doc <- read_html("https://www.google.com")
parsed_doc
Sys.setlocale("LC_ALL", "English")
parsed_doc <- read_html("https://www.google.com")
parsed_doc
# inspect parsed object
class(parsed_doc)
html_structure(parsed_doc)
as_list(parsed_doc)
# import running example
parsed_doc <- read_html("http://www.r-datacollection.com/materials/ch-4-xpath/fortunes/fortunes.html")
parsed_doc
# absolute paths
html_nodes(parsed_doc, xpath = "/html/body/div/p/i")
# relative paths
html_nodes(parsed_doc, xpath = "//body//p/i")
html_nodes(parsed_doc, xpath = "//p/i")
html_nodes(parsed_doc, xpath = "//i")
# wildcard (for ONE node)
html_nodes(parsed_doc, xpath = "/html/body/div/*/i")
html_nodes(parsed_doc, xpath = "/html/body/*/i") # does not work
# ancestor
html_nodes(parsed_doc, xpath = "//a/ancestor::div")
html_nodes(parsed_doc, xpath = "//a/ancestor::div//i")
# sibling
html_nodes(parsed_doc, xpath = "//p/preceding-sibling::h1")
# Parent
html_nodes(parsed_doc, xpath = "//title/parent::*")
# numeric
html_nodes(parsed_doc, xpath = "//div/p[1]")
html_nodes(parsed_doc, xpath =  "//div/p[last()]")
html_nodes(parsed_doc, xpath = "//div[count(.//a)>0]")
html_nodes(parsed_doc, xpath = "//div[count(./@*)>2]")
html_nodes(parsed_doc, xpath = "//*[string-length(text())>50]")
# text-based
html_nodes(parsed_doc, xpath = "//div[@date='October/2011']")
html_nodes(parsed_doc, xpath = "//*[contains(text(), 'magic')]")
html_nodes(parsed_doc, xpath = "//div[starts-with(./@id, 'R')]")
html_nodes(parsed_doc, xpath = "//div[substring-after(./@date, '/')='2003']//i")
# values
html_nodes(parsed_doc, xpath = "//title") %>% html_text()
# attributes
html_nodes(parsed_doc, xpath = "//div") %>% html_attrs() # all attributes
html_nodes(parsed_doc, xpath = "//div") %>% html_attr("lang") # single attribute
